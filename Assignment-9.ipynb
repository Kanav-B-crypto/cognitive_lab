{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbebac2-6fc5-422a-9c95-f31937ea1404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technology is evolving faster than ever from smartphones and ai to space exploration and robotics every innovation is shaping the future\n",
      "it simplifies tasks connects people across the globe and drives efficiency in countless industries\n",
      "as we become more reliant on digital systems understanding technology becomes crucial\n",
      "new breakthroughs continue to amaze and transform the way we live\n",
      "the possibilities are limitless when imagination meets innovation\n",
      "['Technology is evolving faster than ever.', 'From smartphones and AI to space exploration and robotics, every innovation is shaping the future.', 'It simplifies tasks, connects people across the globe, and drives efficiency in countless industries.', 'As we become more reliant on digital systems, understanding technology becomes crucial.', 'New breakthroughs continue to amaze and transform the way we live.', 'The possibilities are limitless when imagination meets innovation.']\n",
      "['Technology', 'is', 'evolving', 'faster', 'than', 'ever', '.', 'From', 'smartphones', 'and', 'AI', 'to', 'space', 'exploration', 'and', 'robotics', ',', 'every', 'innovation', 'is', 'shaping', 'the', 'future', '.', 'It', 'simplifies', 'tasks', ',', 'connects', 'people', 'across', 'the', 'globe', ',', 'and', 'drives', 'efficiency', 'in', 'countless', 'industries', '.', 'As', 'we', 'become', 'more', 'reliant', 'on', 'digital', 'systems', ',', 'understanding', 'technology', 'becomes', 'crucial', '.', 'New', 'breakthroughs', 'continue', 'to', 'amaze', 'and', 'transform', 'the', 'way', 'we', 'live', '.', 'The', 'possibilities', 'are', 'limitless', 'when', 'imagination', 'meets', 'innovation', '.']\n",
      "{'then', 'myself', 'we', \"don't\", 'any', \"doesn't\", 'isn', 'the', 'between', 'an', 'ma', \"it'd\", 'such', 'to', 'our', 'too', 'because', \"they're\", 'under', 'wasn', 'herself', 'will', 'this', 'themselves', 'only', 'now', 'mightn', 'them', 'yourselves', 'have', \"should've\", 'aren', 'during', 'off', 'not', 'some', \"she'd\", 'why', 'i', \"i've\", 'its', 's', \"you'll\", 'is', 'each', \"they've\", 'if', 'should', \"you'd\", 'into', \"you're\", 'can', 'didn', 'with', \"wasn't\", \"hadn't\", \"aren't\", \"haven't\", 'very', 'his', \"she'll\", 'which', \"we'd\", 'she', 'a', 'what', \"didn't\", 'been', \"it's\", 'shan', 'your', 't', 'but', 'most', \"isn't\", \"weren't\", 'nor', 'are', \"shouldn't\", \"i'll\", 'when', \"he's\", 'all', 'has', 'own', 'won', 'again', 'itself', 'her', 'how', 'other', \"they'll\", 'before', 'he', 'and', \"won't\", 'for', 'needn', 'my', 'yourself', 'than', 'here', 'few', 'theirs', 'it', \"shan't\", 'down', 'do', 'of', 'ours', 'their', 'by', 'while', 'about', \"he'd\", 'further', 'from', 'those', 'hasn', 'more', 'as', 'mustn', 'until', \"that'll\", 'they', 'same', 'so', 'was', 'll', 'no', 'ourselves', \"we've\", \"hasn't\", \"it'll\", 'after', 'these', 'or', \"they'd\", \"we're\", 'against', 'him', 'just', 'himself', 'ain', \"needn't\", 'o', 'that', 'haven', 'out', 'am', \"you've\", 'y', 'having', 'whom', 'there', 'does', 'doing', 'below', 'me', 'through', \"he'll\", 'did', \"wouldn't\", 'doesn', \"couldn't\", \"mightn't\", 'weren', 'm', 'had', 'at', 'where', 'up', 'don', 'on', 'above', 'hers', \"she's\", 'couldn', 'both', 're', 'you', \"i'd\", 'yours', \"we'll\", 'be', 'hadn', \"mustn't\", 'shouldn', 'who', 've', 'being', 'once', 'd', \"i'm\", 'over', 'wouldn', 'in', 'were'}\n",
      "['Technology', 'evolving', 'faster', 'ever', '.', 'From', 'smartphones', 'AI', 'space', 'exploration', 'robotics', ',', 'every', 'innovation', 'shaping', 'future', '.', 'It', 'simplifies', 'tasks', ',', 'connects', 'people', 'across', 'globe', ',', 'drives', 'efficiency', 'countless', 'industries', '.', 'As', 'become', 'reliant', 'digital', 'systems', ',', 'understanding', 'technology', 'becomes', 'crucial', '.', 'New', 'breakthroughs', 'continue', 'amaze', 'transform', 'way', 'live', '.', 'The', 'possibilities', 'limitless', 'imagination', 'meets', 'innovation', '.']\n",
      "Technology: 1\n",
      "evolving: 1\n",
      "faster: 1\n",
      "ever: 1\n",
      ".: 6\n",
      "From: 1\n",
      "smartphones: 1\n",
      "AI: 1\n",
      "space: 1\n",
      "exploration: 1\n",
      "robotics: 1\n",
      ",: 4\n",
      "every: 1\n",
      "innovation: 2\n",
      "shaping: 1\n",
      "future: 1\n",
      "It: 1\n",
      "simplifies: 1\n",
      "tasks: 1\n",
      "connects: 1\n",
      "people: 1\n",
      "across: 1\n",
      "globe: 1\n",
      "drives: 1\n",
      "efficiency: 1\n",
      "countless: 1\n",
      "industries: 1\n",
      "As: 1\n",
      "become: 1\n",
      "reliant: 1\n",
      "digital: 1\n",
      "systems: 1\n",
      "understanding: 1\n",
      "technology: 1\n",
      "becomes: 1\n",
      "crucial: 1\n",
      "New: 1\n",
      "breakthroughs: 1\n",
      "continue: 1\n",
      "amaze: 1\n",
      "transform: 1\n",
      "way: 1\n",
      "live: 1\n",
      "The: 1\n",
      "possibilities: 1\n",
      "limitless: 1\n",
      "imagination: 1\n",
      "meets: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kanav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kanav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords');\n",
    "paragraph = \"\"\"Technology is evolving faster than ever. From smartphones and AI to space exploration and robotics, every innovation is shaping the future.\n",
    "It simplifies tasks, connects people across the globe, and drives efficiency in countless industries.\n",
    "As we become more reliant on digital systems, understanding technology becomes crucial.\n",
    "New breakthroughs continue to amaze and transform the way we live.\n",
    "The possibilities are limitless when imagination meets innovation.\"\"\"\n",
    "\n",
    "clean_paragraph=paragraph.lower()\n",
    "clean_paragraph=clean_paragraph.translate(str.maketrans('','',string.punctuation))\n",
    "print(clean_paragraph)\n",
    "\n",
    "sentence=sent_tokenize(paragraph)\n",
    "words=word_tokenize(paragraph)\n",
    "print(sentence)\n",
    "print(words)\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "filtered_words=[word for word in words if word not in stop_words]\n",
    "print(filtered_words)\n",
    "\n",
    "freq_dist = FreqDist(filtered_words)\n",
    "for word,freq in freq_dist.items():\n",
    "    print(word + \": \" + str(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1031454e-a063-4467-b328-659492f0463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "technology -> technolog , technolog\n",
      "evolving -> evolv , evolv\n",
      "faster -> faster , fast\n",
      "ever -> ever , ev\n",
      "smartphones -> smartphon , smartphon\n",
      "ai -> ai , ai\n",
      "space -> space , spac\n",
      "exploration -> explor , expl\n",
      "robotics -> robot , robot\n",
      "every -> everi , every\n",
      "innovation -> innov , innov\n",
      "shaping -> shape , shap\n",
      "future -> futur , fut\n",
      "simplifies -> simplifi , simpl\n",
      "tasks -> task , task\n",
      "connects -> connect , connect\n",
      "people -> peopl , peopl\n",
      "across -> across , across\n",
      "globe -> globe , glob\n",
      "drives -> drive , driv\n",
      "efficiency -> effici , efficy\n",
      "countless -> countless , countless\n",
      "industries -> industri , industry\n",
      "become -> becom , becom\n",
      "reliant -> reliant , rely\n",
      "digital -> digit , digit\n",
      "systems -> system , system\n",
      "understanding -> understand , understand\n",
      "technology -> technolog , technolog\n",
      "becomes -> becom , becom\n",
      "crucial -> crucial , cruc\n",
      "new -> new , new\n",
      "breakthroughs -> breakthrough , breakthrough\n",
      "continue -> continu , continu\n",
      "amaze -> amaz , amaz\n",
      "transform -> transform , transform\n",
      "way -> way , way\n",
      "live -> live , liv\n",
      "possibilities -> possibl , poss\n",
      "limitless -> limitless , limitless\n",
      "imagination -> imagin , imagin\n",
      "meets -> meet , meet\n",
      "innovation -> innov , innov\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lemmatized result is :-\n",
      "technology -> technology\n",
      "evolving -> evolving\n",
      "faster -> faster\n",
      "ever -> ever\n",
      "smartphones -> smartphones\n",
      "ai -> ai\n",
      "space -> space\n",
      "exploration -> exploration\n",
      "robotics -> robotics\n",
      "every -> every\n",
      "innovation -> innovation\n",
      "shaping -> shaping\n",
      "future -> future\n",
      "simplifies -> simplifies\n",
      "tasks -> task\n",
      "connects -> connects\n",
      "people -> people\n",
      "across -> across\n",
      "globe -> globe\n",
      "drives -> drive\n",
      "efficiency -> efficiency\n",
      "countless -> countless\n",
      "industries -> industry\n",
      "become -> become\n",
      "reliant -> reliant\n",
      "digital -> digital\n",
      "systems -> system\n",
      "understanding -> understanding\n",
      "technology -> technology\n",
      "becomes -> becomes\n",
      "crucial -> crucial\n",
      "new -> new\n",
      "breakthroughs -> breakthrough\n",
      "continue -> continue\n",
      "amaze -> amaze\n",
      "transform -> transform\n",
      "way -> way\n",
      "live -> live\n",
      "possibilities -> possibility\n",
      "limitless -> limitless\n",
      "imagination -> imagination\n",
      "meets -> meet\n",
      "innovation -> innovation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kanav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kanav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kanav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,WordNetLemmatizer\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "paragraph = \"\"\"Technology is evolving faster than ever. From smartphones and AI to space exploration and robotics, every innovation is shaping the future.\n",
    "It simplifies tasks, connects people across the globe, and drives efficiency in countless industries.\n",
    "As we become more reliant on digital systems, understanding technology becomes crucial.\n",
    "New breakthroughs continue to amaze and transform the way we live.\n",
    "The possibilities are limitless when imagination meets innovation.\"\"\"\n",
    "\n",
    "clean_text = paragraph.lower()\n",
    "clean_text = clean_text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "words = word_tokenize(clean_text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "# main question from here\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "porter_stems=[porter.stem(word) for word in filtered_words]\n",
    "lancaster_stems = [lancaster.stem(word) for word in filtered_words]\n",
    "print()\n",
    "\n",
    "for word in filtered_words:\n",
    "    print(word + \" -> \" + porter.stem(word) + \" , \" + lancaster.stem(word))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Lemmatized result is :-\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for word in filtered_words:\n",
    "    print(word + \" -> \" + lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "760a5a57-8625-48c6-ad46-b16a3761107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Technology', 'evolving', 'faster', 'smartphones', 'exploration', 'robotics', 'innovation', 'shaping', 'future', 'simplifies', 'connects', 'people', 'across', 'drives', 'efficiency', 'countless', 'industries', 'become', 'reliant', 'digital', 'systems', 'understanding', 'technology', 'becomes', 'crucial', 'breakthroughs', 'continue', 'transform', 'possibilities', 'limitless', 'imagination', 'innovation']\n",
      "[]\n",
      "['Technology', 'From', 'AI', 'It', 'As', 'New', 'The']\n",
      "['Technology', 'is', 'evolving', 'faster', 'than', 'ever', 'From', 'smartphones', 'and', 'AI', 'to', 'space', 'exploration', 'and', 'robotics', 'every', 'innovation', 'is', 'shaping', 'the', 'future', 'It', 'simplifies', 'tasks', 'connects', 'people', 'across', 'the', 'globe', 'and', 'drives', 'efficiency', 'in', 'countless', 'industries', 'As', 'we', 'become', 'more', 'reliant', 'on', 'digital', 'systems', 'understanding', 'technology', 'becomes', 'crucial', 'New', 'breakthroughs', 'continue', 'to', 'amaze', 'and', 'transform', 'the', 'way', 'we', 'live', 'The', 'possibilities', 'are', 'limitless', 'when', 'imagination', 'meets', 'innovation']\n",
      "['is', 'evolving', 'ever', 'and', 'AI', 'exploration', 'and', 'every', 'innovation', 'is', 'It', 'across', 'and', 'efficiency', 'in', 'industries', 'As', 'on', 'understanding', 'amaze', 'and', 'are', 'imagination', 'innovation']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "paragraph= \"\"\"Technology is evolving faster than ever. From smartphones and AI to space exploration and robotics, every innovation is shaping the future.\n",
    "It simplifies tasks, connects people across the globe, and drives efficiency in countless industries.\n",
    "As we become more reliant on digital systems, understanding technology becomes crucial.\n",
    "New breakthroughs continue to amaze and transform the way we live.\n",
    "The possibilities are limitless when imagination meets innovation.\"\"\"\n",
    "\n",
    "greater_than_five = re.findall(r'\\b[a-zA-Z]{6,}\\b',paragraph)\n",
    "print(greater_than_five)\n",
    "\n",
    "numbers=re.findall(r'\\b\\d+\\b',paragraph)\n",
    "print(numbers)\n",
    "\n",
    "capitalized=re.findall(r'\\b[A-Z][a-zA-Z]*\\b',paragraph)\n",
    "print(capitalized)\n",
    "\n",
    "alphabets=re.findall(r'\\b[a-zA-Z]+\\b',paragraph)\n",
    "print(alphabets)\n",
    "\n",
    "vowels=[word for word in alphabets if re.match(r'^[aeiouAEIOU]',word)]\n",
    "print(vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc03ae0-b51d-4010-91b6-187c0b79d792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
